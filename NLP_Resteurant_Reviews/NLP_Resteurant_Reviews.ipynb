{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika natural_language_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU-pjQ8a2zFu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdlvVT2F3cvT"
      },
      "source": [
        "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter= '\\t', quoting= 3 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "## Cleaning the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iIxcxSa4kd5",
        "outputId": "7c999a9b-4f18-4300-8065-e69a9573407a"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "corpus = []\n",
        "for i in range(0,1000):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  ps = PorterStemmer()\n",
        "  all_stopwords = stopwords.words('english')\n",
        "  all_stopwords.remove('not')\n",
        "  all_stopwords.remove(\"isn't\")\n",
        "  review = [ps.stem(word) for word in review if not word in set (all_stopwords)]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "## Creating the Bag of Words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11DYgz8sF8yM"
      },
      "source": [
        "# print(corpus)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = dataset.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-p1gYO1ocng"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size =0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orMvEsunfUeI"
      },
      "source": [
        "FP = [0]*10\n",
        "FN = [0]*10\n",
        "TP = [0]*10\n",
        "TN = [0]*10\n",
        "P = [0]*10\n",
        "R = [0]*10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QRw_iWyfW9_"
      },
      "source": [
        "#Accuracy Calculation\n",
        "def accuracy(TP, TN, FP, FN):\n",
        "  return (TP + TN) * 100/ (TP + TN + FN + FP)\n",
        "\n",
        "#Precision Calculation\n",
        "def precision(TP, FP):\n",
        "  P[i] = TP/ (TP + FP)\n",
        "  return P[i] * 100\n",
        "\n",
        "#Recall Calculation\n",
        "def recall(TP, FN):\n",
        "  R[i] = TP/(TP +FN)\n",
        "  return R[i] * 100\n",
        "\n",
        "#F!_score Calculation\n",
        "def F1_score(P, R):\n",
        "  return (2 * P * R * 100)/ (P + R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIq23vEDIPt"
      },
      "source": [
        "## Training the Logistic Regression Model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ta9bRPzfbNw"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier_LR = LogisticRegression(random_state = 0)\n",
        "classifier_LR.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_LR.predict(x_test))\n",
        "FN[0] = cm[1][0]\n",
        "FP[0] = cm[0][1]\n",
        "TP[0] = cm[0][0]\n",
        "TN[0] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7R6044ifnFW"
      },
      "source": [
        "# Training the KNN Model on the Training set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbPcGfCkfqHP"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier_KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier_KNN.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_KNN.predict(x_test))\n",
        "FN[1] = cm[1][0]\n",
        "FP[1] = cm[0][1]\n",
        "TP[1] = cm[0][0]\n",
        "TN[1] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJw0Vcrff6Rb"
      },
      "source": [
        "# Training the SVM Model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LoF64lvf5dI"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier_SVC = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier_SVC.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_SVC.predict(x_test))\n",
        "FN[2] = cm[1][0]\n",
        "FP[2] = cm[0][1]\n",
        "TP[2] = cm[0][0]\n",
        "TN[2] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpAhDs3nf-qi"
      },
      "source": [
        "# Training the Kernel SVM Model on the Trining set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-DTkeEpgB_2"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier_KSVC = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier_KSVC.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_KSVC.predict(x_test))\n",
        "FN[3] = cm[1][0]\n",
        "FP[3] = cm[0][1]\n",
        "TP[3] = cm[0][0]\n",
        "TN[3] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6sVCkHhgFQu"
      },
      "source": [
        "# Training the Naive Bayes model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xql_8b97gHTx"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier_NB = GaussianNB()\n",
        "classifier_NB.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_NB.predict(x_test))\n",
        "FN[4] = cm[1][0]\n",
        "FP[4] = cm[0][1]\n",
        "TP[4] = cm[0][0]\n",
        "TN[4] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rHqY2_UgJhS"
      },
      "source": [
        "# Training the Decision Tree Classification Model on the Trining set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ccl5NXgNh7"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier_DTC = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier_DTC.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_DTC.predict(x_test))\n",
        "FN[5] = cm[1][0]\n",
        "FP[5] = cm[0][1]\n",
        "TP[5] = cm[0][0]\n",
        "TN[5] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-O50bK7gP6a"
      },
      "source": [
        "# Training the Random Forest Classification Model on the Trining set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSO9bvNvgb06"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier_RFC = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)\n",
        "classifier_RFC.fit(x_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, classifier_RFC.predict(x_test))\n",
        "FN[6] = cm[1][0]\n",
        "FP[6] = cm[0][1]\n",
        "TP[6] = cm[0][0]\n",
        "TN[6] = cm[1][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXKCtM4MgeeU"
      },
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-06a-tSgggO0",
        "outputId": "1196a2d1-1710-4f9f-9ca7-c6c80d0a7ef3"
      },
      "source": [
        "r2_dict = {\n",
        "    'Logistic Regression' : FN[0],\n",
        "    'KNN' : FN[1],\n",
        "    'SVM': FN[2],\n",
        "    'Kernel SVM' : FN[3],\n",
        "    'Naive Bayes' : FN[4],\n",
        "    'Decision Tree' : FN[5],\n",
        "    'Random Forest' : FN[6]\n",
        "}\n",
        "\n",
        "#default values\n",
        "best = 100\n",
        "best_name = 'Winner Winner Chicken Dinner!!'\n",
        "\n",
        "#printing table of results\n",
        "print(\"{: <40} {: <20} {: <20} {: <20} {: <20} {: <20}\".format('Classification Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'False Positive'))\n",
        "print('-' * 130)\n",
        "i = 0\n",
        "for key, val in r2_dict.items():\n",
        "  if best > val:\n",
        "    best = val\n",
        "    best_name = key\n",
        "  print(\"{: <40} {: <20} {: <20} {: <20} {: <20} {: <20}\".format(key, accuracy(TP[i], TN[i], FP[i], FN[i]), precision(TP[i], FP[i]), recall(TP[i], FN[i]), F1_score(P[i], R[i] ), val ))\n",
        "  i = i + 1\n",
        "\n",
        "#Printing the best model\n",
        "print('-' * 130)\n",
        "print(best_name, 'model gave the best results as it had ', best, ' number of False Negatives which are considered as Dangerous for any model.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Model                     Accuracy             Precision            Recall               F1 Score             False Positive      \n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Logistic Regression                      77.5                 82.4742268041237     74.07407407407408    78.04878048780486    28                  \n",
            "KNN                                      64.0                 68.04123711340206    61.6822429906542     64.70588235294117    41                  \n",
            "SVM                                      80.0                 81.44329896907216    78.21782178217822    79.79797979797979    22                  \n",
            "Kernel SVM                               77.5                 91.75257731958763    70.63492063492063    79.8206278026906     37                  \n",
            "Naive Bayes                              73.0                 56.70103092783505    82.08955223880598    67.07317073170731    12                  \n",
            "Decision Tree                            74.5                 81.44329896907216    70.53571428571429    75.59808612440192    33                  \n",
            "Random Forest                            76.5                 91.75257731958763    69.53125             79.11111111111111    39                  \n",
            "----------------------------------------------------------------------------------------------------------------------------------\n",
            "Naive Bayes model gave the best results as it had  12  number of False Negatives which are considered as Dangerous for any model.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}